---
title: "FY25 Official Forecasting for FY26 Foundation Payment: ETS + Percentage-Based (PCT) Methods"
author: "Kristen Mosley"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: flatly
    toc: true
    toc_float: true
    toc_depth: 3
    number_sections: true
    code_folding: hide
    df_print: paged
params:
  raw_data: "data/CCF_FundYear25 09OCT25.xlsx" # <-- edit this file to test different outputs based on different outcome counts
  osa_data: "data/CCF OSA ad-hoc data collection 2020-2022.xlsx"
  iclc_data: "data/CCF ICLC ad-hoc data collection 2020-2024.xlsx"
  merged_data: "data/CCF_FundYear25 09OCT25_merged.xlsx" # <-- cleaned and merged raw data to incorporate CCF ad-hoc ICLC and OSA data collection
  forecasts: "ets-forecasts/fy25-official-ets-forecasts.xlsx"
  existing_outliers: "final-forecasts/fy25-official-forecast-outliers.xlsx"
  final_forecasts: "final-forecasts/fy25-official-all-forecasts.xlsx"# <-- final ETS & PCT forecasts
---

# Document Summary

This document brings together the two forecasting approaches used by the Coordinating Board to project future student outcomes: the **Exponential Triple Smoothing (ETS) method** and the **Percentage-based (PCT) method**. 

It first runs the ETS forecasting process to determine forecasts for student outcomes not defined as high-demand or specified for a student subgroup (e.g., academic disadvantage). **ETS forecasting produces 12 forecast outputs.** Then, it applies the PCT forecasting process to determine high-demand field and student subgroup outcomes. **PCT forecasting produces 63 forecast outputs.** 

The final combined forecast outputs, which integrate both methods, are saved in the final-forecasts/ folder for input in the funding model.

A **quality control (QC) process** is built-in throughout the forecasting model to provide plain-language messaging for each step of the process. If any step fails, the process will stop and provide a message indicating the issue. Warnings and informational messages are also provided to track the progress of the model.

# Load Packages
```{r pkgs, message = FALSE, warning = FALSE}
options(width = 999)
knitr::opts_chunk$set(warning = FALSE, cache = FALSE, tidy = FALSE)

# Load necessary packages
library(tidyverse)
library(tsibble)
library(fable)
library(fabletools)
library(knitr)
library(openxlsx)
library(purrr)
library(kableExtra)
library(ggplot2)
library(feasts)
```


# Import, Merge, and Clean Historical Data
```{r tsdata_load}
# Clean and merge data function
# Reads raw data, merges in OSA/ICLC data, outputs combined Excel, returns tsibble
# Cleans and prepares the dataset for forecasting
# Identifies historical data gaps with "NA"
# @param raw_file Path to raw data Excel file
# @param osa_file Path to OSA Excel file
# @param iclc_file Path to ICLC Excel file
# @param output_file Path to save combined Excel file
# @return Cleaned tsibble ready for forecasting
clean_and_merge_data <- function(
  raw_file = params$raw_data,
  osa_file = params$osa_data,
  iclc_file = params$iclc_data,
  output_file = params$merged_data
) {
  # QC: Check historical data found
  if(!file.exists(params$raw_data)){
  stop(paste0("❌ Raw Data Import Error. Please check file path:", params$raw_data))
  } else {
  message("✅ Raw Data Import: ", params$raw_data)}
  if(!file.exists(params$osa_data)){
  stop(paste0("❌ OSA Data Import Error. Please check file path:", params$osa_data))
  } else {
  message("✅ OSA Data Import: ", params$osa_data)}
  if(!file.exists(params$iclc_data)){
  stop(paste0("❌ ICLC Data Import Error. Please check file path:", params$iclc_data))
  } else {
  message("✅ ICLC Data Import: ", params$iclc_data)}

  # Read raw and ad-hoc data
  raw_data <- read.xlsx(params$raw_data)
  osa <- read.xlsx(params$osa_data)
  iclc <- read.xlsx(params$iclc_data)
    
  # Clean column names
  colnames(raw_data) <- make.names(colnames(raw_data))
  colnames(osa) <- make.names(colnames(osa))
  colnames(iclc) <- make.names(colnames(iclc))
  
  # Update COV premium column names in DMR data
  raw_data <- raw_data %>%
    mutate(TOTAL.Certificate.I.or.II..COV.Premium = cert.prem,
           TOTAL.Associate..CoV.Premium = assoc.prem,
           TOTAL.Bachelor.s.Degree..CoV.Premium = bach.prem,
           .keep = "unused")
  
  # Isolate DMR OSA data 2023-24
  osadmr <- raw_data %>% 
    select(FICE:Year, TOTAL.OSA:OSA..High.Demand.Field...Adult.Learner) %>% 
    filter(between(Year, 2023, 2024))
  
  # QC: Check that OSA columns exist
  if (!any(str_detect(names(osadmr), "^TOTAL\\.OSA"))) {
    stop("❌ QC Check Failed: No OSA-related columns found in OSA DMR data")
  } else {
    message("✅ QC Passed: OSA-related columns found in OSA DMR data")
  }
  
  # QC: Check that only 2023 and 2024 data were captured
  unique_years <- unique(osadmr$Year)
  if (!all(unique_years %in% c(2023, 2024))) {
    stop(paste0("❌ QC Check Failed: OSA DMR data includes unexpected years: ",
                paste(unique_years, collapse = ", ")))
  } else {
    message("✅ QC Passed: OSA DMR data correctly limited to 2023–24 data.")
  }  
  
  # Identify which columns in osadmr are OSA-specific (not ID fields)
  id_cols <- c("FICE", "Institution", "Year")
  osa_cols <- setdiff(names(osadmr), id_cols)

  # QC: Ensure OSA columns were successfully identified
  if (length(osa_cols) == 0) {
    stop("❌ QC Check Failed: No OSA-specific columns identified in OSA DMR data")
  } else {
    message(paste0("✅ QC Passed: Identified ", length(osa_cols),
                   " OSA-specific columns to remove from raw_data."))
  }
  
  # Remove OSA columns from raw_data
  raw_data <- raw_data %>%
    select(-any_of(osa_cols))
  
  # QC: Confirm columns were removed
  if (any(osa_cols %in% names(raw_data))) {
    stop("❌ QC Check Failed: OSA columns still present in raw_data after removal.")
  } else {
    message("✅ QC Passed: OSA columns successfully removed from raw_data.")
  }
  
  # Merge CCF ad-hoc OSA data & DMR OSA data
  osa <- osa %>% 
    rbind(osadmr)
  
  # Merge combined OSA data with raw data
  raw_data <- raw_data %>% 
    left_join(osa, by = c("FICE", "Institution", "Year")) %>% 
    #relocate osa columns
    relocate(TOTAL.OSA:`OSA..High.Demand.Field...Adult.Learner`, .before = TOTAL.Certificate.I.or.II)
  
  # Merge ICLC ad-hoc data
  combined_data <- raw_data %>%
    left_join(iclc, by = c("FICE", "Institution", "Year")) %>%
    relocate(contains("Institutional"),
               .before = TOTAL.OSA) %>% 
    # Create Type column and mark historical rows
    mutate(Type = "Historical", .after = Year) %>% 
    #relocate COV premium columns
    relocate(TOTAL.Certificate.I.or.II..COV.Premium, .before = TOTAL.Bachelor.s.Degree..CoV.Premium) %>% 
    relocate(TOTAL.Associate..CoV.Premium, .before = TOTAL.Bachelor.s.Degree..CoV.Premium)
  
  # QC check ncols of combined_data == 79 (4 ID columns, 75 student outcomes)
  if(ncol(combined_data) != 79){
  stop(paste0("❌ QC Check Failed: Combined Data Column Count Error. Expected 79, found ", ncol(combined_data), "."))
  } else {
  message("✅ QC Passed: Combined Data Column Count Correct.")}
    
  # Output combined data to Excel
  write.xlsx(combined_data, file = params$merged_data, overwrite = TRUE)
    
  # QC check for output file
  if(!file.exists(params$iclc_data)){
  stop(paste0("❌ QC Check Failed: Combined Data Export Error."))
  } else {
  message("✅ QC Passed: Combined Data Export Successfully: ", params$merged_data)}
 
  # Convert to tsibble
  tsdata <- combined_data %>%
    as_tsibble(key = c("FICE", "Institution"), index = "Year")
    
  return(tsdata)
}

# Run clean and merge function

tsdata <- clean_and_merge_data(
  params$raw_data,
  params$osa_data,
  params$iclc_data,
  params$merged_data
)
```

# Recent Historical Data Check
```{r check_recent_years}
# Historical data Check: Compare Most Recent Two Historical Years
# Compares last and second-last historical years (e.g., 2023 vs 2024)
# Flags large absolute and % changes, using same thresholds as outlier QC

check_recent_year_changes <- function(
  tsdata,
  abs_threshold = 20,
  pct_threshold = 0.25,
  min_val = 50
) {
  # Ensure tsdata is a regular tibble (not a tsibble) for joins
  df <- as_tibble(tsdata)
  
  # Identify the two most recent historical years
  recent_years <- sort(unique(df$Year), decreasing = TRUE)
  if (length(recent_years) < 2) {
    stop("❌ Not enough historical years to perform historical data check.")
  }
  most_recent <- recent_years[1]
  second_recent <- recent_years[2]
  message(paste0("ℹ️ Comparing ", second_recent, " → ", most_recent, " for historical data check."))

  # Identify numeric variables to compare
  vars <- setdiff(names(df), c("FICE", "Institution", "Year", "Type"))

  # Subset data for the two years
  data_recent <- df %>% 
    filter(Year == most_recent) %>% 
    select(FICE, Institution, all_of(vars))
  data_prev   <- df %>% 
    filter(Year == second_recent) %>% 
    select(FICE, Institution, all_of(vars))

  # Join on FICE + Institution
  comp <- left_join(data_recent, data_prev, by = c("FICE", "Institution"), suffix = c("_curr", "_prev"))

  # Compute per variable with a pivot_longer after join
  comp_long <- comp %>%
    pivot_longer(
      cols = -c(FICE, Institution),
      names_to = c("Variable", ".value"),
      names_pattern = "(.*)_(curr|prev)") %>%
    mutate(
      abs_diff = abs(curr - prev),
      denom = ifelse(is.na(prev) | prev == 0, 1, abs(prev)),
      pct_diff = pmin(abs_diff / denom, 1)) %>%
    filter(!is.na(curr) & !is.na(prev)) %>%
    filter(curr >= min_val | prev >= min_val)

  # Outliers
  outliers_df <- comp_long %>%
    filter(abs_diff > abs_threshold & pct_diff > pct_threshold) %>%
    # Rename curr/prev to actual year values dynamically
    rename(
      !!paste0(second_recent) := prev,
      !!paste0(most_recent) := curr
    )

  # Messages
  outlier_rate <- if (nrow(comp_long) > 0) nrow(outliers_df) / nrow(comp_long) else 0
  msg_text <- sprintf(
    "%d out of %d (%0.1f%%) year-to-year changes exceed %d absolute and %.0f%% relative thresholds.",
    nrow(outliers_df), nrow(comp_long), 100 * outlier_rate, abs_threshold, 100 * pct_threshold
  )
  if (outlier_rate > 0.05) message(paste0("⚠️ ", msg_text)) else message(paste0("ℹ️", msg_text))
  
  return(outliers_df %>% 
           select(FICE, Institution, Variable, !!paste0(second_recent), !!paste0(most_recent), abs_diff, pct_diff))
}

# Run the recent-year historical data check
historical_outliers <- check_recent_year_changes(tsdata)

# QC: Create table for outlier information
if (exists("historical_outliers") && nrow(historical_outliers) > 0) {
  historical_outlier_table <- historical_outliers %>%
    select(FICE, Institution, Variable, `2023`, `2024`, abs_diff, pct_diff) %>%
  mutate(
    pct_diff = round(pct_diff * 100, 0),
    pct_diff = paste0(pct_diff, "%")) %>%
    arrange(desc(pct_diff))


  # Show top outlier information
  kable(
    head(historical_outlier_table, 20), 
    caption = "Top 20 Historical Data Outliers by Outlier Percentage Difference",
    align = c("l", "l", "l", "c", "c", "c", "c") # left for cols 1-3, center for 4-7
  )
} else {
  log_qc("ℹ️ No outliers detected in forecast vs. 2024 comparison.", "INFO", "Outlier QC")
}

# Save to Excel
output_file <- "data/fy25-historical-data-outliers.xlsx"
write.xlsx(historical_outliers, file = output_file, overwrite = TRUE)

# QC message
if (file.exists(output_file)) {
  message("✅ Exported historical data check outlier table to ", output_file)
} else {
  message("❌ Failed to write recent-year historical data check outliers.")
}

```

# Run ETS Forecast
```{r run_ets_child, child='fy25-official-ets-forecast.Rmd'}

```

# Run PCT Forecast
```{r run_pct_child, child='fy25-official-pct-forecast.Rmd'}

```

# Compile Forecasts
* 400 rows expected (50 institutions x 8 years)
* 79 columns expected (4 ID columns + 75 forecast outputs)
```{r compile_fcs}
# Rename output with all forecasts
final_dataset <- fc_all

# QC: Check variable names match original data
expected_vars <- colnames(tsdata)
if(!all(expected_vars %in% colnames(final_dataset))){
  stop("Variable names mismatch! Check child RMD outputs.")
} else {
  message("✅ Variable names match")
}

# QC: Check row counts of all forecasts output
expected_rows <- nrow(final_dataset)
if(expected_rows != (nrow(tsdata) + 50)){  # Assuming 50 forecast rows added for FY25
  stop("Row count mismatch! Check child RMD outputs.")
} else {
  message("✅ Row count matches expected: ", expected_rows)
}

# QC: Check column counts of all forecasts output
expected_cols <- ncol(final_dataset)
if(expected_cols != (ncol(tsdata))){  # Assuming 4 factor columns + 75 outputs
  stop("Column count mismatch! Check child RMD outputs.")
} else {
  message("✅Column count matches expected: ", expected_cols)
}

# QC: Check NAs do not exist in forecast rows
if(any(is.na(final_dataset %>% filter(Type == "ETS")))){
  stop("NAs found in ETS forecast rows! Please investigate.")
} else {
  message("✅ No NAs found in ETS forecast rows.")
}

```

# Save Final Output
```{r final_output}
# Save final output to Excel in final-forecasts/ 
write.xlsx(final_dataset, file = params$final_forecasts, overwrite = TRUE)

# QC: Check files saved
message("✅ Final unified forecast saved to: ", params$final_forecasts)

```

# High-Level Review
```{r fc_review}
# Load final forecasts
final_forecasts <- read.xlsx(params$final_forecasts)

# Pivot longer
forecasts_long <- final_forecasts %>%
  pivot_longer(
    cols = -c(FICE, Institution, Year, Type),
    names_to = "variable",
    values_to = "forecast"
  )
forecasts_long <- forecasts_long %>%
  mutate(
    outcome_variable = case_when(
      str_detect(variable, "Certificate.I") ~ "Certificate.I.or.II",
      str_detect(variable, "Institutional") ~ "ICLC",
      str_detect(variable, "Associate") ~ "Associate",
      str_detect(variable, "Bachelor") ~ "Bachelor's",
      str_detect(variable, "OSA") ~ "OSA",
      str_detect(variable, "Transfer") ~ "Transfer",
      str_detect(variable, "Co.enroll") ~ "Coenroll",
      str_detect(variable, "Advanced") ~ "ATC",
      str_detect(variable, "Dual") ~ "Dual.Credit",
      TRUE ~ "Other"
    )
  )

# Filter to only include forecasts for Year == 2025
forecast_summary <- forecasts_long %>%
  filter(Year == 2025) %>%
  group_by(outcome_variable) %>%
  summarise(
    mean_forecast = mean(forecast, na.rm = TRUE),
    median_forecast = median(forecast, na.rm = TRUE),
    sd_forecast = sd(forecast, na.rm = TRUE),
    .groups = "drop"
  )


# Boxplot (only 2025)
ggplot(forecasts_long %>% filter(Year == 2025),
       aes(x = outcome_variable, y = forecast, fill = outcome_variable)) +
  geom_boxplot(outlier.alpha = 0.2) +
  theme_minimal() +
  labs(
    title = "Distribution of Forecasts by Outcome Category (2025)",
    x = "Outcome Category",
    y = "Forecast Value"
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))



```

